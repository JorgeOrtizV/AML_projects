{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data and save to vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train_df = pd.read_csv('./data/X_train.csv', skiprows=1, header=None)\n",
    "y_train_df = pd.read_csv('./data/y_train.csv', skiprows=1, header=None)\n",
    "X_test_df = pd.read_csv('./data/X_test.csv', skiprows=1, header=None)\n",
    "\n",
    "X_train_full = X_train_df.values[:, 1:]\n",
    "y_train_full = y_train_df.values[:, 1:]\n",
    "X_test = X_test_df.values[:, 1:]\n",
    "\n",
    "print(X_train_full.shape, y_train_full.shape, X_test.shape)\n",
    "\n",
    "# Normalize data\n",
    "scaler = StandardScaler()\n",
    "X_train_full = scaler.fit_transform(X_train_full)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The matrix below serves to see how many features seem useful, adjusting k_param\n",
    "\n",
    "If you see many entries with all correlations around 0 (column or row all 0, then k_param is too high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "k_param = 40\n",
    "\n",
    "X_train = X_train_full\n",
    "y_train = y_train_full\n",
    "\n",
    "X_impute = np.nanmean(X_train, axis=0, keepdims=True)\n",
    "X_train = np.where(np.isnan(X_train), X_impute, X_train)\n",
    "\n",
    "selector = SelectKBest(mutual_info_regression, k=k_param)\n",
    "X_selected = selector.fit_transform(X_train, y_train)\n",
    "\n",
    "corr_matrix = np.corrcoef(X_selected.T)\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(corr_matrix, cmap=\"coolwarm\", annot=False, square=True, cbar=True)\n",
    "plt.title(\"Correlation Matrix Heatmap of Selected Features\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and validation set\n",
    "Used a 70-30 split, can be changed at `testSize=0.3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "testSize = 0.3\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size = testSize, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this if no validation set wanted\n",
    "X_train = X_train_full\n",
    "y_train = y_train_full\n",
    "X_val = X_train \n",
    "y_val = y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing missing values with ...\n",
    "\n",
    "Using mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values with mean\n",
    "X_impute = np.nanmean(X_train, axis=0, keepdims=True)\n",
    "X_train = np.where(np.isnan(X_train), X_impute, X_train)\n",
    "X_train_full = np.where(np.isnan(X_train_full), X_impute, X_train_full)\n",
    "X_val = np.where(np.isnan(X_val), X_impute, X_val)\n",
    "X_test = np.where(np.isnan(X_test), X_impute, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using knn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=30)\n",
    "X_train = imputer.fit_transform(X_train)\n",
    "\n",
    "X_train = imputer.transform(X_train)\n",
    "X_train_full = imputer.transform(X_train_full)\n",
    "X_val = imputer.transform(X_val)\n",
    "X_test = imputer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection (dropping certain features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_param = 30 #number of features to selct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using SelectKBest from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression\n",
    "\n",
    "# Select `k_param` features with highest mutual info\n",
    "selection = SelectKBest(mutual_info_regression, k=k_param).fit(X_train, y_train)\n",
    "X_train = selection.transform(X_train)\n",
    "X_train_full = selection.transform(X_train_full)\n",
    "X_val = selection.transform(X_val)\n",
    "X_test = selection.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using recursive feature elimination (takes a while to run):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "\n",
    "model = Ridge()\n",
    "rfe = RFE(estimator=model, n_features_to_select=k_param)\n",
    "X_train = rfe.fit_transform(X_train, y_train)\n",
    "X_train_full = rfe.transform(X_train_full)\n",
    "X_val = rfe.transform(X_val)\n",
    "X_test = rfe.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to recursive feature elimination, but with lasso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "eps = 0.001\n",
    "\n",
    "model = Lasso(alpha=0.1)\n",
    "model.fit(X_train, y_train)\n",
    "selected_features = (model.coef_ > eps)\n",
    "X_train = X_train[:, selected_features]\n",
    "X_train_full = X_train_full[:, selected_features]\n",
    "X_val = X_val[:, selected_features]\n",
    "X_test = X_test[:, selected_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using SVD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components=k_param)\n",
    "\n",
    "X_train = svd.fit_transform(X_train)\n",
    "X_train_full = svd.transform(X_train_full)\n",
    "X_val = svd.transform(X_val)\n",
    "X_test = svd.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using PCA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=k_param)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_train_full = pca.transform(X_train_full)\n",
    "X_val = pca.transform(X_val)\n",
    "X_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isolation forest (good for large datasets with unknown distributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "iso_forest = IsolationForest(contamination=0.05)\n",
    "outliers = iso_forest.fit_predict(X_train)\n",
    "X_train = X_train[outliers == 1]\n",
    "y_train = y_train[outliers == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "one_class_svm = OneClassSVM(nu=0.05, kernel=\"rbf\", gamma=0.1)\n",
    "outliers = one_class_svm.fit_predict(X_train)\n",
    "X_train = X_train[outliers == 1]\n",
    "y_train = y_train[outliers == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using z-score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "\n",
    "outlier_param = 5\n",
    "\n",
    "z_scores = zscore(X_train)\n",
    "outliers = np.abs(z_scores) > outlier_param\n",
    "\n",
    "X_train = X_train[(~outliers).all(axis=1)]\n",
    "y_train = y_train[(~outliers).all(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IQR (taking everything in [Q1-1.5IQR, Q3+1.5IQR]):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = np.percentile(X_train, 25, axis=0)\n",
    "Q3 = np.percentile(X_train, 75, axis=0)\n",
    "IQR = Q3 - Q1\n",
    "alpha = 2\n",
    "\n",
    "lower_bound = Q1 - alpha * IQR\n",
    "upper_bound = Q3 + alpha * IQR\n",
    "outliers = (X_train < lower_bound) | (X_train > upper_bound)\n",
    "X_train = X_train[(~outliers).all(axis=1)]\n",
    "y_train = y_train[(~outliers).all(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Train a linear regression model\n",
    "linearRegressor = LinearRegression()\n",
    "linearRegressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For lasso and ridge we first determine the best alpha value to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Determine best alpha value\n",
    "alpha_values = [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "lasso_param_grid = {'alpha': alpha_values}\n",
    "ridge_param_grid = {'alpha': alpha_values}\n",
    "\n",
    "lasso = Lasso()\n",
    "ridge = Ridge()\n",
    "\n",
    "lasso_search = GridSearchCV(lasso, lasso_param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "ridge_search = GridSearchCV(ridge, ridge_param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "lasso_search.fit(X_train, y_train)\n",
    "ridge_search.fit(X_train, y_train)\n",
    "\n",
    "best_alpha_lasso = lasso_search.best_params_['alpha']\n",
    "best_alpha_ridge = ridge_search.best_params_['alpha']\n",
    "print(best_alpha_lasso)\n",
    "print(best_alpha_ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then train the model using that alpha value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lassoRegressor = Lasso(alpha=best_alpha_lasso)\n",
    "ridgeRegressor = Ridge(alpha=best_alpha_ridge)\n",
    "\n",
    "lassoRegressor.fit(X_train, y_train)\n",
    "ridgeRegressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run predictions\n",
    "Run predictions and obtain r2 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "lin_y_train_pred = linearRegressor.predict(X_train)\n",
    "lin_y_val_pred = linearRegressor.predict(X_val)\n",
    "lin_train_score = r2_score(y_train, lin_y_train_pred)\n",
    "lin_val_score = r2_score(y_val, lin_y_val_pred)\n",
    "print('Linear regression score:')\n",
    "print(lin_train_score, lin_val_score)\n",
    "print('\\n')\n",
    "\n",
    "lasso_y_train_pred = lassoRegressor.predict(X_train)\n",
    "lasso_y_val_pred = lassoRegressor.predict(X_val)\n",
    "lasso_train_score = r2_score(y_train, lasso_y_train_pred)\n",
    "lasso_val_score = r2_score(y_val, lasso_y_val_pred)\n",
    "print('Lasso regression score:')\n",
    "print(lasso_train_score, lasso_val_score)\n",
    "print('\\n')\n",
    "\n",
    "ridge_y_train_pred = ridgeRegressor.predict(X_train)\n",
    "ridge_y_val_pred = ridgeRegressor.predict(X_val)\n",
    "ridge_train_score = r2_score(y_train, ridge_y_train_pred)\n",
    "ridge_val_score = r2_score(y_val, ridge_y_val_pred)\n",
    "print('Ridge regression score:')\n",
    "print(ridge_train_score, ridge_val_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting to required format for Kaggle\n",
    "y_train_pred = lassoRegressor.predict(X_train_full)\n",
    "print(r2_score(y_train_full, y_train_pred))\n",
    "\n",
    "table = pd.DataFrame({'id': np.arange(0, y_train_pred.shape[0]), 'y': y_train_pred.flatten()})\n",
    "table.to_csv('./data/y_train_pred.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting to required format for Kaggle\n",
    "y_test_pred = regressor.predict(X_test)\n",
    "\n",
    "table = pd.DataFrame({'id': np.arrange(0, y_test_pred.shape[0]), 'y': y_test_pred.flatten()})\n",
    "table.to_csv('./data/y_test_pred.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
