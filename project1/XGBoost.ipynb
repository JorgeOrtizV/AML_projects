{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4aca2e3-d1ff-4461-886d-e5ffb94d8c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (969, 832) X_val:  (243, 832)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "X_train_df = pd.read_csv('./data/X_train.csv', skiprows=1, header=None)\n",
    "y_train_df = pd.read_csv('./data/y_train.csv', skiprows=1, header=None)\n",
    "X_test_df = pd.read_csv('./data/X_test.csv', skiprows=1, header=None)\n",
    "\n",
    "X_train = X_train_df.values[:, 1:]\n",
    "y_train = y_train_df.values[:, 1:].ravel()\n",
    "X_test  = X_test_df.values[:, 1:]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train,test_size=0.2, random_state=42)\n",
    "print(\"X_train: \", X_train.shape, \"X_val: \", X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98297e0-0e45-423b-b39d-14018e9db316",
   "metadata": {},
   "source": [
    "Imputing with mean values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "571dfab8-d242-4fe1-aa43-d93ec2816468",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "mean_imputer = SimpleImputer(strategy='mean')\n",
    "X_train_imputed = mean_imputer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326ce0ec-ae5f-4f01-9b95-209f0e2402a6",
   "metadata": {},
   "source": [
    "Outlier Detection with LOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21ead4ea-6a66-43ac-b750-d434eccd2da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered X_train shape: (920, 832)\n",
      "Filtered y_train shape: (920,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
    "\n",
    "lof = LocalOutlierFactor(n_neighbors=20, contamination=0.05)\n",
    "outlier_labels = lof.fit_predict(X_train_scaled)\n",
    "\n",
    "X_train_cleaned = X_train_imputed[outlier_labels == 1] # imputed data after detecting\n",
    "X_train = X_train[outlier_labels == 1] # original data after detecting\n",
    "y_train = y_train[outlier_labels == 1]\n",
    "\n",
    "print(\"Filtered X_train shape:\", X_train_cleaned.shape)\n",
    "print(\"Filtered y_train shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a4405d-d671-4887-8ce4-2acce932c46f",
   "metadata": {},
   "source": [
    "Feature selection f-scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a393342a-30b0-4fb7-9b23-f21d6c534d47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of significant features: 230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\PyTorch\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:379: RuntimeWarning: invalid value encountered in sqrt\n",
      "  X_norms = np.sqrt(row_norms(X.T, squared=True) - n_samples * X_means**2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "selector = SelectKBest(score_func=f_regression, k='all')\n",
    "selector.fit(X_train_cleaned, y_train.ravel())\n",
    "\n",
    "p_values = selector.pvalues_\n",
    "scores = selector.scores_\n",
    "\n",
    "significant_feature_indices = np.where(p_values < 0.05)[0]\n",
    "\n",
    "print(f\"Number of significant features: {len(significant_feature_indices)}\")\n",
    "\n",
    "# Extract selected features from the original data\n",
    "X_train_selected = X_train[:, significant_feature_indices]\n",
    "X_val_selected = X_val[:, significant_feature_indices]\n",
    "X_test_selected = X_test[:, significant_feature_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe0b12c-e50a-4cec-8d6d-d6dd42b4a144",
   "metadata": {},
   "source": [
    "Impute missing values in the selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "932db48b-c539-4f69-bd0f-fb7d2f0f2e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "iterative_imputer = IterativeImputer()\n",
    "X_train_selected_imputed = iterative_imputer.fit_transform(X_train_selected)\n",
    "X_val_selected_imputed = iterative_imputer.transform(X_val_selected)\n",
    "X_test_selected_imputed = iterative_imputer.transform(X_test_selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d99d17d-9863-4cc4-90d5-43008a3425d8",
   "metadata": {},
   "source": [
    "Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0946b748-9e16-40ce-84d3-56ce953564b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_selected_imputed)\n",
    "X_val_scaled = scaler.transform(X_val_selected_imputed)\n",
    "X_test_scaled = scaler.transform(X_test_selected_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02e856b4-bde0-4468-956c-a6288555f7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R^2 Score: 0.9997811445232354\n",
      "Validation R^2 Score: 0.547337378272673\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "xgb_model = XGBRegressor(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05, \n",
    "    max_depth=5,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    gamma=0.1, \n",
    "    reg_alpha=0.5, \n",
    "    reg_lambda=1.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_train_pred = xgb_model.predict(X_train_scaled)\n",
    "y_val_pred = xgb_model.predict(X_val_scaled)\n",
    "y_test_pred = xgb_model.predict(X_test_scaled)\n",
    "\n",
    "print(\"Train R^2 Score:\", r2_score(y_train, y_train_pred))\n",
    "print(\"Validation R^2 Score:\", r2_score(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab90319e-a9eb-4031-a0d3-86b815966b95",
   "metadata": {},
   "source": [
    "Overfitting is quite serious, but no better solution has been found yet..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178273bf-2847-4d66-9cf6-cb91640fdca7",
   "metadata": {},
   "source": [
    "CVS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cb3d62-27af-41af-8bfc-5733defbc54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.DataFrame({'id': np.arange(0, y_test_pred.shape[0]), 'y': y_test_pred.flatten()})\n",
    "print(table.shape)\n",
    "table.to_csv('./data/predictions/y_test_pred.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
