{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19137,
     "status": "ok",
     "timestamp": 1734384051847,
     "user": {
      "displayName": "ZILU XIAO",
      "userId": "10761288573105859344"
     },
     "user_tz": -60
    },
    "id": "LLf5-lvud6U7",
    "outputId": "aa3bab5b-ad46-4b59-8f99-7cc3a60626a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 2883,
     "status": "ok",
     "timestamp": 1734384054729,
     "user": {
      "displayName": "ZILU XIAO",
      "userId": "10761288573105859344"
     },
     "user_tz": -60
    },
    "id": "QIxJZFNMfGXJ"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 9536,
     "status": "ok",
     "timestamp": 1734384064263,
     "user": {
      "displayName": "ZILU XIAO",
      "userId": "10761288573105859344"
     },
     "user_tz": -60
    },
    "id": "ziGk5S5feE1l"
   },
   "outputs": [],
   "source": [
    "with open('data/train_expert.pkl', 'rb') as f:\n",
    "    train_expert = pickle.load(f)\n",
    "with open('data/train_amateur.pkl', 'rb') as f:\n",
    "    train_amateur = pickle.load(f)\n",
    "with open('data/val_expert.pkl', 'rb') as f:\n",
    "    val_expert = pickle.load(f)\n",
    "with open('data/val_amateur.pkl', 'rb') as f:\n",
    "    val_amateur = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1734384064263,
     "user": {
      "displayName": "ZILU XIAO",
      "userId": "10761288573105859344"
     },
     "user_tz": -60
    },
    "id": "GuJwrup2gx2J"
   },
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=1):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        def conv_block(in_ch, out_ch):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "\n",
    "        self.encoder1 = conv_block(in_channels, 64)\n",
    "        self.encoder2 = conv_block(64, 128)\n",
    "        self.encoder3 = conv_block(128, 256)\n",
    "        self.encoder4 = conv_block(256, 512)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.bottleneck = conv_block(512, 1024)\n",
    "\n",
    "        self.upconv4 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
    "        self.decoder4 = conv_block(1024, 512)\n",
    "        self.upconv3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.decoder3 = conv_block(512, 256)\n",
    "        self.upconv2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.decoder2 = conv_block(256, 128)\n",
    "        self.upconv1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.decoder1 = conv_block(128, 64)\n",
    "\n",
    "        self.final_conv = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        e1 = self.encoder1(x)\n",
    "        e2 = self.encoder2(self.pool(e1))\n",
    "        e3 = self.encoder3(self.pool(e2))\n",
    "        e4 = self.encoder4(self.pool(e3))\n",
    "\n",
    "        # Bottleneck\n",
    "        b = self.bottleneck(self.pool(e4))\n",
    "\n",
    "        # Decoder\n",
    "        d4 = self.upconv4(b)\n",
    "        d4 = torch.cat((e4, d4), dim=1)\n",
    "        d4 = self.decoder4(d4)\n",
    "\n",
    "        d3 = self.upconv3(d4)\n",
    "        d3 = torch.cat((e3, d3), dim=1)\n",
    "        d3 = self.decoder3(d3)\n",
    "\n",
    "        d2 = self.upconv2(d3)\n",
    "        d2 = torch.cat((e2, d2), dim=1)\n",
    "        d2 = self.decoder2(d2)\n",
    "\n",
    "        d1 = self.upconv1(d2)\n",
    "        d1 = torch.cat((e1, d1), dim=1)\n",
    "        d1 = self.decoder1(d1)\n",
    "\n",
    "        # Final output\n",
    "        out = self.final_conv(d1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=1):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        def conv_block(in_ch, out_ch):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1),\n",
    "                #nn.BatchNorm2d(out_ch),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1),\n",
    "                #nn.BatchNorm2d(out_ch),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "\n",
    "        self.encoder1 = conv_block(in_channels, 64)\n",
    "        self.encoder2 = conv_block(64, 128)\n",
    "        self.encoder3 = conv_block(128, 256)\n",
    "        self.encoder4 = conv_block(256, 512)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.bottleneck = conv_block(512, 1024)\n",
    "        self.bottleneck2 = conv_block(1024, 1024)\n",
    "        self.bottleneck3 = conv_block(1024, 1024)\n",
    "\n",
    "        self.upconv4 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
    "        self.decoder4 = conv_block(1024, 512)\n",
    "        self.upconv3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.decoder3 = conv_block(512, 256)\n",
    "        self.upconv2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.decoder2 = conv_block(256, 128)\n",
    "        self.upconv1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.decoder1 = conv_block(128, 64)\n",
    "\n",
    "        self.final_conv = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        e1 = self.encoder1(x)\n",
    "        e2 = self.encoder2(self.pool(e1))\n",
    "        e3 = self.encoder3(self.pool(e2))\n",
    "        e4 = self.encoder4(self.pool(e3))\n",
    "\n",
    "        # Bottleneck\n",
    "        b = self.bottleneck(self.pool(e4))\n",
    "        b2 = self.bottleneck2(b)\n",
    "        b3 = self.bottleneck3(b2)\n",
    "\n",
    "        # Decoder\n",
    "        d4 = self.upconv4(b2)\n",
    "        d4 = torch.cat((e4, d4), dim=1)\n",
    "        d4 = self.decoder4(d4)\n",
    "\n",
    "        d3 = self.upconv3(d4)\n",
    "        d3 = torch.cat((e3, d3), dim=1)\n",
    "        d3 = self.decoder3(d3)\n",
    "\n",
    "        d2 = self.upconv2(d3)\n",
    "        d2 = torch.cat((e2, d2), dim=1)\n",
    "        d2 = self.decoder2(d2)\n",
    "\n",
    "        d1 = self.upconv1(d2)\n",
    "        d1 = torch.cat((e1, d1), dim=1)\n",
    "        d1 = self.decoder1(d1)\n",
    "\n",
    "        # Final output\n",
    "        out = self.final_conv(d1)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1734384064264,
     "user": {
      "displayName": "ZILU XIAO",
      "userId": "10761288573105859344"
     },
     "user_tz": -60
    },
    "id": "bggcCtqD3JUo"
   },
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.25, gamma=2.0):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        probs = torch.sigmoid(logits)\n",
    "        targets = targets.float()\n",
    "\n",
    "        ce_loss = nn.BCEWithLogitsLoss(reduction='none')(logits, targets)\n",
    "        p_t = probs * targets + (1 - probs) * (1 - targets)\n",
    "        focal_weight = self.alpha * (1 - p_t) ** self.gamma\n",
    "\n",
    "        loss = focal_weight * ce_loss\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 4328,
     "status": "ok",
     "timestamp": 1734384068590,
     "user": {
      "displayName": "ZILU XIAO",
      "userId": "10761288573105859344"
     },
     "user_tz": -60
    },
    "id": "v_uXunurhcIG"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.transforms.functional import resize\n",
    "class MitralDataset(Dataset):\n",
    "    def __init__(self, data, target_size=(512, 512)):\n",
    "        self.data = data\n",
    "        self.target_size = target_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        frame = self.data[idx]['frame']\n",
    "        label = self.data[idx]['label']\n",
    "        box = self.data[idx]['box']\n",
    "\n",
    "        frame_tensor = torch.tensor(frame, dtype=torch.float32).unsqueeze(0)\n",
    "        label_tensor = torch.tensor(label, dtype=torch.float32).unsqueeze(0)\n",
    "        box_tensor = torch.tensor(box, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "        frame_tensor = resize(frame_tensor, self.target_size)\n",
    "        label_tensor = resize(label_tensor, self.target_size)\n",
    "        box_tensor = resize(box_tensor, self.target_size)\n",
    "\n",
    "\n",
    "        return frame_tensor, label_tensor, box_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1734384068590,
     "user": {
      "displayName": "ZILU XIAO",
      "userId": "10761288573105859344"
     },
     "user_tz": -60
    },
    "id": "8oDn91IHhlt1"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_expert_dataset = MitralDataset(train_expert)\n",
    "val_expert_dataset = MitralDataset(val_expert)\n",
    "\n",
    "train_loader = DataLoader(train_expert_dataset, batch_size=6, shuffle=True)\n",
    "val_loader = DataLoader(val_expert_dataset, batch_size=6, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1734384068590,
     "user": {
      "displayName": "ZILU XIAO",
      "userId": "10761288573105859344"
     },
     "user_tz": -60
    },
    "id": "5Y5l3Yc1ifvJ"
   },
   "outputs": [],
   "source": [
    "model = UNet()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "criterion = FocalLoss(alpha=0.25, gamma=2.0)\n",
    "epochs = 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1734384068590,
     "user": {
      "displayName": "ZILU XIAO",
      "userId": "10761288573105859344"
     },
     "user_tz": -60
    },
    "id": "VMTJPh-Nijtp"
   },
   "outputs": [],
   "source": [
    "def calculate_iou(predictions, labels):\n",
    "    predictions = predictions.bool()\n",
    "    labels = labels.bool()\n",
    "\n",
    "    intersection = (predictions & labels).sum(dim=(1, 2, 3))\n",
    "    union = (predictions | labels).sum(dim=(1, 2, 3))\n",
    "\n",
    "    iou = intersection / (union + 1e-8)\n",
    "    return iou.mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1184160,
     "status": "ok",
     "timestamp": 1734385252748,
     "user": {
      "displayName": "ZILU XIAO",
      "userId": "10761288573105859344"
     },
     "user_tz": -60
    },
    "id": "bs9w9u-7jUvY",
    "outputId": "c09e47b0-eada-4682-db76-ce46d6d4b609"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                           | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Loss: 0.0228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|██                                                             | 1/30 [17:44<8:34:33, 1064.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Validation IoU: 0.0000\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    for images, labels, _ in train_loader:\n",
    "        images, labels= images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {epoch_loss / len(train_loader):.4f}\")\n",
    "\n",
    "    # Evaluate IoU on validation set\n",
    "    model.eval()\n",
    "    total_iou = 0.0\n",
    "    with torch.no_grad():\n",
    "        for val_images, val_labels,_ in val_loader:\n",
    "            val_images, val_labels = val_images.to(device), val_labels.to(device)\n",
    "            output = model(val_images)\n",
    "            val_predictions = (torch.sigmoid(output) > 0.5).float()\n",
    "            total_iou += calculate_iou(val_predictions, val_labels)\n",
    "    avg_iou = total_iou / len(val_loader)\n",
    "    print(f\"Epoch [{epoch + 1}/{epochs}], Validation IoU: {avg_iou:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 9090,
     "status": "ok",
     "timestamp": 1734385261836,
     "user": {
      "displayName": "ZILU XIAO",
      "userId": "10761288573105859344"
     },
     "user_tz": -60
    },
    "id": "O4aLr5wikUaO"
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "with gzip.open('data/test.pkl', 'rb') as f:\n",
    "    test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1734385261836,
     "user": {
      "displayName": "ZILU XIAO",
      "userId": "10761288573105859344"
     },
     "user_tz": -60
    },
    "id": "IDBoelKxxfAQ"
   },
   "outputs": [],
   "source": [
    "# def get_sequences(arr):\n",
    "#     first_indices, last_indices, lengths = [], [], []\n",
    "#     n, i = len(arr), 0\n",
    "#     arr = [0] + list(arr) + [0]\n",
    "#     for index, value in enumerate(arr[:-1]):\n",
    "#         if arr[index+1]-arr[index] == 1:\n",
    "#             first_indices.append(index)\n",
    "#         if arr[index+1]-arr[index] == -1:\n",
    "#             last_indices.append(index)\n",
    "#     lengths = list(np.array(last_indices)-np.array(first_indices))\n",
    "#     return first_indices, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 386,
     "status": "ok",
     "timestamp": 1734385536358,
     "user": {
      "displayName": "ZILU XIAO",
      "userId": "10761288573105859344"
     },
     "user_tz": -60
    },
    "id": "PCwZYkfHbvG7"
   },
   "outputs": [],
   "source": [
    "def get_sequences(arr):\n",
    "    arr = np.concatenate(([0], arr, [0]))\n",
    "    changes = np.diff(arr)\n",
    "    starts = np.where(changes == 1)[0]\n",
    "    ends = np.where(changes == -1)[0]\n",
    "    lengths = ends - starts\n",
    "    return starts, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 397,
     "status": "ok",
     "timestamp": 1734385539436,
     "user": {
      "displayName": "ZILU XIAO",
      "userId": "10761288573105859344"
     },
     "user_tz": -60
    },
    "id": "y6Yx8Gj2Iybo"
   },
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, test_data):\n",
    "        self.test_data = test_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.test_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        video_name = self.test_data[idx]['name']\n",
    "        video_frames = self.test_data[idx]['video']\n",
    "\n",
    "        frames_tensor = torch.tensor(video_frames, dtype=torch.float32).permute(2, 0, 1)\n",
    "\n",
    "        return video_name, frames_tensor\n",
    "\n",
    "test_dataset = TestDataset(test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 125760,
     "status": "ok",
     "timestamp": 1734385666259,
     "user": {
      "displayName": "ZILU XIAO",
      "userId": "10761288573105859344"
     },
     "user_tz": -60
    },
    "id": "h9WPXZvnid9K"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from torchvision.transforms.functional import resize\n",
    "\n",
    "model.eval()\n",
    "submission_data = []\n",
    "threshold = 0.5\n",
    "with torch.no_grad():\n",
    "    for video_name, frames_tensor in test_loader:\n",
    "        video_name = video_name[0]\n",
    "        frames_tensor = frames_tensor.squeeze(0).to(device)  # [num_frames, H, W]\n",
    "        num_frames, original_height, original_width = frames_tensor.shape\n",
    "        target_size = (512, 512)\n",
    "\n",
    "        labels_tensor = torch.zeros((num_frames, original_height, original_width), dtype=torch.uint8)\n",
    "\n",
    "        for frame_idx in range(num_frames):\n",
    "\n",
    "            frame = frames_tensor[frame_idx].unsqueeze(0).unsqueeze(0)  # [1, 1, H, W]\n",
    "            resized_frame = resize(frame, target_size).to(device)      # [1, 1, 512, 512]\n",
    "\n",
    "\n",
    "            output = model(resized_frame)  # [1, 1, 512, 512]\n",
    "            predicted_mask = torch.sigmoid(output).squeeze().cpu().numpy()  # [512, 512]\n",
    "\n",
    "            restored_mask = cv2.resize(predicted_mask, (original_width, original_height), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "            labels_tensor[frame_idx] = torch.from_numpy((restored_mask > threshold).astype(np.uint8))\n",
    "\n",
    "\n",
    "        labels_tensor = labels_tensor.permute(1, 2, 0)  # [H, W, num_frames]\n",
    "\n",
    "        flattened_labels = labels_tensor.flatten()\n",
    "        start_indices, lengths = get_sequences(flattened_labels)\n",
    "\n",
    "        record_counter = 0\n",
    "        for start_idx, length in zip(start_indices, lengths):\n",
    "            submission_data.append({\n",
    "                \"id\": f\"{video_name}_{record_counter}\",\n",
    "                \"value\": f\"[{start_idx}, {length}]\"\n",
    "            })\n",
    "            record_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 611,
     "status": "ok",
     "timestamp": 1734385679094,
     "user": {
      "displayName": "ZILU XIAO",
      "userId": "10761288573105859344"
     },
     "user_tz": -60
    },
    "id": "AcTQ1K3AQs84",
    "outputId": "9c4b715f-0865-4739-9f30-39f838dcfdc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 'E9AHVWGBUF_0', 'value': '[9100158, 1]'}, {'id': 'E9AHVWGBUF_1', 'value': '[9100261, 1]'}, {'id': 'E9AHVWGBUF_2', 'value': '[9100364, 1]'}, {'id': 'E9AHVWGBUF_3', 'value': '[9100467, 1]'}, {'id': 'E9AHVWGBUF_4', 'value': '[9100570, 1]'}, {'id': 'E9AHVWGBUF_5', 'value': '[9184721, 1]'}, {'id': 'E9AHVWGBUF_6', 'value': '[9184824, 1]'}, {'id': 'E9AHVWGBUF_7', 'value': '[9184927, 1]'}, {'id': 'E9AHVWGBUF_8', 'value': '[9185030, 1]'}, {'id': 'E9AHVWGBUF_9', 'value': '[9185133, 1]'}]\n"
     ]
    }
   ],
   "source": [
    "print(submission_data[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 405,
     "status": "ok",
     "timestamp": 1734385690163,
     "user": {
      "displayName": "ZILU XIAO",
      "userId": "10761288573105859344"
     },
     "user_tz": -60
    },
    "id": "4kQILrs5vLgy",
    "outputId": "f7dc0335-0a11-4d36-c12f-c26600191aea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "932132\n"
     ]
    }
   ],
   "source": [
    "print(len(submission_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 1935,
     "status": "ok",
     "timestamp": 1734385694566,
     "user": {
      "displayName": "ZILU XIAO",
      "userId": "10761288573105859344"
     },
     "user_tz": -60
    },
    "id": "8tBL3wG1JYZk"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(submission_data)\n",
    "df.to_csv(\"predictions2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "aborted",
     "timestamp": 1734385466109,
     "user": {
      "displayName": "ZILU XIAO",
      "userId": "10761288573105859344"
     },
     "user_tz": -60
    },
    "id": "jsqh16j0d9wf"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMd3FNjD5MqOU0ZJJc+OcxE",
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
