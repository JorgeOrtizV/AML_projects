{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "362c4939",
   "metadata": {},
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9cc66686",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from biosppy.signals import ecg\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0f3786a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('original_data/train.csv', index_col='id')\n",
    "train_y = data['y']\n",
    "labels = train_y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e7f7d6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See if there is any difference between using the filtered heartbeats or not\n",
    "with open('data/heartbeat_templates_ecg.pkl', 'rb') as f:\n",
    "    heartbeats = pickle.load(f)\n",
    "    \n",
    "# with open('data/heartbeat_filtered_ecg.pkl', 'rb') as f:\n",
    "#     heartbeats = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b7d98d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(32)\n",
    "\n",
    "def split_indices(n, val_pct):\n",
    "    n_val = int(val_pct*n)\n",
    "    idxs = np.random.permutation(n)\n",
    "    return idxs[n_val:], idxs[:n_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5f40786a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SignalDataset(Dataset):\n",
    "    def __init__(self, signals, lengths, labels):\n",
    "        self.signals = signals\n",
    "        self.labels = labels\n",
    "        self.lengths = lengths\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.signals)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.signals[idx], self.lengths[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a2930d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159\n"
     ]
    }
   ],
   "source": [
    "## Be sure that all the heartbeats have the same length\n",
    "\n",
    "# Longest seq of beats\n",
    "max_length_heartbeats = max([len(i) for i in heartbeats])\n",
    "beat_length = 180 # All heartbeats have the same length\n",
    "\n",
    "# Padded heartbeats\n",
    "padded_heartbeats = []\n",
    "lengths = []\n",
    "\n",
    "print(max_length_heartbeats)\n",
    "\n",
    "for heartbeat in heartbeats:\n",
    "    length = len(heartbeat)\n",
    "    lengths.append(length)\n",
    "    pad = np.zeros((max_length_heartbeats-length, 180))\n",
    "    padded_heartbeats.append(np.concatenate((heartbeat, pad),axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "007bdd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform heartbeats to tensor\n",
    "padded_heartbeats = np.array(padded_heartbeats)\n",
    "padded_heartbeats = torch.tensor(padded_heartbeats, dtype=torch.float32)\n",
    "labels_heartbeats = torch.tensor(labels)\n",
    "lengths_heartbeats = torch.tensor(lengths)\n",
    "\n",
    "# Train val split\n",
    "train_idxs, val_idxs = split_indices(len(padded_heartbeats), 0.2)\n",
    "train_x = padded_heartbeats[train_idxs]\n",
    "val_y = labels_heartbeats[val_idxs]\n",
    "train_y = labels_heartbeats[train_idxs]\n",
    "val_x = padded_heartbeats[val_idxs]\n",
    "train_lengths = lengths_heartbeats[train_idxs]\n",
    "val_lengths = lengths_heartbeats[val_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "336a4b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make a dataset for all the individual beats - 1D conv\n",
    "\n",
    "labels_beats = []\n",
    "beats = []\n",
    "\n",
    "for i, beat in enumerate(heartbeats):\n",
    "    samples = beat.shape[0]\n",
    "    beats.append(torch.tensor(beat, dtype=torch.float32))\n",
    "    labels_beats.append(torch.full((samples,), labels[i]))\n",
    "    \n",
    "beats = torch.cat(beats, dim=0)\n",
    "labels_beats = torch.cat(labels_beats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "737dba2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train - val split for individual beats\n",
    "\n",
    "train_idxs_beats, val_idxs_beats = split_indices(len(beats), 0.2)\n",
    "train_x_beats = beats[train_idxs_beats]\n",
    "val_y_beats = labels_beats[val_idxs_beats]\n",
    "train_y_beats = labels_beats[train_idxs_beats]\n",
    "val_x_beats = beats[val_idxs_beats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b4a0bdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the moment training without a scaler but try also with scaler later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4e8e4d",
   "metadata": {},
   "source": [
    "### Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9eaf4c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Signal dataset\n",
    "class SignalDataset(Dataset):\n",
    "    def __init__(self, signals, lengths, labels):\n",
    "        self.signals = signals\n",
    "        self.labels = labels\n",
    "        self.lengths = lengths\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.signals)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.signals[idx], self.lengths[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2c1ca3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SignalDataset(train_x, train_lengths, train_y)\n",
    "val_dataset = SignalDataset(val_x, val_lengths, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a8722d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "def collate_fn(batch):\n",
    "    signals, lengths, labels = zip(*batch)\n",
    "    signals = torch.stack(signals)\n",
    "    lengths = torch.stack(lengths)\n",
    "    labels = torch.stack(labels)\n",
    "    signals = signals.to(device)\n",
    "    lengths = lengths.to(device)\n",
    "    attention_mask = torch.arange(signals.size(1), device=device).unsqueeze(0) >= lengths.unsqueeze(1)\n",
    "    return signals, attention_mask, labels\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d5ca0e",
   "metadata": {},
   "source": [
    "# Transformer for signal beats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "de11663d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model:int, seq_len:int, dropout:float):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.seq_len = seq_len\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        pe = torch.zeros(seq_len, d_model) #(seq_len, d_model)\n",
    "        \n",
    "        position = torch.arange(0, seq_len, dtype=torch.float).unsqueeze(1) #(seq_len, 1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float()*(-math.log(10000.0)/d_model))\n",
    "        pe[:,0::2] = torch.sin(position*div_term)\n",
    "        pe[:,1::2] = torch.cos(position*div_term)\n",
    "        \n",
    "        pe = pe.unsqueeze(0) #(1, seq_len, d_model)\n",
    "        \n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + (self.pe[:, :x.shape[1], :]).requires_grad_(False)\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "12b5103e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, eps:float = 10**-6):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.eps = eps\n",
    "        self.alpha = nn.Parameter(torch.ones(1))\n",
    "        self.bias = nn.Parameter(torch.zeros(1))\n",
    "        \n",
    "    def forward(self,x):\n",
    "        mean = x.mean(dim=-1, keepdim=True) # We use the last dimension\n",
    "        std = x.std(dim=-1, keepdim=True)\n",
    "        return self.alpha*(x-mean)/(std+self.eps)+self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "2fce7499",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedFwd(nn.Module):\n",
    "    def __init__(self, d_model:int, d_ff:int, dropout:float):\n",
    "        super(FeedFwd, self).__init__()\n",
    "        self.linear1 = nn.Linear(d_model, d_ff)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear2 = nn.Linear(d_ff, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # (b_size, seq_len, d_model) -> (b_size, seq_len, dff) -> (b_size, seq_len, d_model)\n",
    "        x = self.relu(self.linear1(x))\n",
    "        x = self.dropout(self.linear2(x))\n",
    "        return x\n",
    "        #return self.linear2(self.dropout(self.linear1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "aacfbdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiheadAttention(nn.Module):\n",
    "    def __init__(self, d_model:int, h:int, dropout:float): # h -> num heads\n",
    "        super(MultiheadAttention, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.h = h\n",
    "        assert d_model % h == 0, \"d_model is not divisible by h\"\n",
    "        \n",
    "        self.d_k = d_model // h # dim of each head\n",
    "        \n",
    "        self.w_q = nn.Linear(d_model, d_model)\n",
    "        self.w_k = nn.Linear(d_model, d_model)\n",
    "        self.w_v = nn.Linear(d_model, d_model)\n",
    "        \n",
    "        self.w_o = nn.Linear(d_model, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    @staticmethod\n",
    "    def attention(query, key, value, mask, dropout):\n",
    "        d_k = query.shape[-1]\n",
    "        attention_scores = (query @ key.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "        if mask != None:\n",
    "            mask = mask.unsqueeze(1).unsqueeze(2) # (b_size, 1, 1, seq_len) -> make this to match the attention_Score size\n",
    "            attention_scores.masked_fill_(mask == 0, -1e9)\n",
    "        attention_scores = attention_scores.softmax(dim=-1) # (b_size, h, seq_len, seq_len)\n",
    "        if dropout != None:\n",
    "            attention_scores = dropout(attention_scores)\n",
    "            \n",
    "        return (attention_scores@value), attention_scores\n",
    "        \n",
    "    def forward(self, q, k, v, mask):\n",
    "        query = self.w_q(q) # (b_size, seq_len, d_model) -> (b_size, seq_len, d_model)\n",
    "        key = self.w_k(k)\n",
    "        val = self.w_v(v)\n",
    "        \n",
    "        query = query.view(query.shape[0], query.shape[1], self.h, self.d_k).transpose(1,2) # Divide to heads\n",
    "        key = key.view(key.shape[0], key.shape[1], self.h, self.d_k).transpose(1,2)\n",
    "        val = val.view(val.shape[0], val.shape[1], self.h, self.d_k).transpose(1,2)\n",
    "        # Outpus size at this point (b_size, h, seq_len, d_k)\n",
    "        \n",
    "        # Apply mask\n",
    "        x, self.attention_scores = MultiheadAttention.attention(query, key, val, mask, self.dropout)\n",
    "        \n",
    "        x = x.transpose(1,2).contiguous().view(x.shape[0], -1, self.h*self.d_k) # Go back to (b_size, seq_len, h, d_k) and then (b_size, seq_len, d_model)\n",
    "        \n",
    "        return self.w_o(x) # (b_size, seq_len, d_model)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "f05f84f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualConnection(nn.Module):\n",
    "    def __init__(self, dropout:float):\n",
    "        super(ResidualConnection, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.norm = LayerNorm()\n",
    "        \n",
    "    def forward(self, x, sublayer):\n",
    "        return x + self.dropout(sublayer(self.norm(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "e0f020d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, self_attention, feed_forward, dropout):\n",
    "        super(EncoderBlock, self).__init__()\n",
    "        self.self_attention = self_attention\n",
    "        self.feed_forward = feed_forward\n",
    "        self.residual_connections = nn.ModuleList([ResidualConnection(dropout) for _ in range(2)])\n",
    "\n",
    "    \n",
    "    def forward(self, x, src_mask):\n",
    "        x = self.residual_connections[0](x, lambda x: self.self_attention(x, x, x, src_mask))\n",
    "        x = self.residual_connections[1](x, self.feed_forward)\n",
    "        return x\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "c618dc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.layers = layers\n",
    "        self.norm = LayerNorm()\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "0073c0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, encoder, pos_enc, src_size, d_model, output_dim):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.pos_enc = pos_enc\n",
    "        self.input_proj = nn.Linear(src_size, d_model)\n",
    "        self.out_proj = nn.Linear(d_model, output_dim)\n",
    "        \n",
    "    def encode(self, src, src_mask):\n",
    "        src = self.input_proj(src)\n",
    "        src = self.pos_enc(src)\n",
    "        encoder_output = self.encoder(src, src_mask)\n",
    "        # MLP\n",
    "        pre_out = encoder_output.mean(dim=1) #Avg pooling over seq length -> really helpful?\n",
    "        logits = self.out_proj(pre_out)\n",
    "        return logits\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "3cd97a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_transformer(src_size, src_seq_len, d_model=512, N=6, h=8, dropout=0.1, d_ff=2048, output_dim=4):\n",
    "    # Positional encoding\n",
    "    pe = PositionalEncoding(d_model, src_seq_len, dropout)\n",
    "    # Encoder\n",
    "    encoder_blocks = []\n",
    "    for _ in range(N):\n",
    "        encoder_self_attention = MultiheadAttention(d_model, h, dropout)\n",
    "        feed_fwd = FeedFwd(d_model, d_ff, dropout)\n",
    "        encoder_block = EncoderBlock(encoder_self_attention, feed_fwd, dropout)\n",
    "        encoder_blocks.append(encoder_block)\n",
    "        \n",
    "    encoder = Encoder(nn.ModuleList(encoder_blocks))\n",
    "    \n",
    "    transformer = Transformer(encoder, pe, src_size, d_model, output_dim)\n",
    "    \n",
    "    for p in transformer.parameters():\n",
    "        if p.dim()>1:\n",
    "            nn.init.xavier_uniform_(p)\n",
    "            \n",
    "    return transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ca71cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▌                                                                              | 1/50 [07:51<6:25:13, 471.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100] | Train Loss: 1.1060 | Validation Loss: 0.9921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|███▏                                                                            | 2/50 [15:39<6:15:41, 469.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/100] | Train Loss: 0.9336 | Validation Loss: 0.9402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|████▊                                                                           | 3/50 [23:24<6:05:57, 467.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/100] | Train Loss: 0.9054 | Validation Loss: 0.9318\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "d_model = 512\n",
    "nhead = 8\n",
    "num_encoder_layers=3\n",
    "num_decoder_layers = 0\n",
    "dim_feedforward = 2048\n",
    "dropout = 0.1\n",
    "output_dim = 4\n",
    "LR = 1e-4\n",
    "EPOCHS = 50\n",
    "\n",
    "model = build_transformer(src_size=180, src_seq_len=max_length_heartbeats, d_model=d_model, N=num_encoder_layers, h=nhead, dropout=dropout, d_ff=dim_feedforward, output_dim=4)\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    model.train()\n",
    "    train_loss=0\n",
    "    for batch in train_dataloader:\n",
    "        inputs, attention_mask, targets = batch\n",
    "        inputs = inputs.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        targets = targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model.encode(inputs, attention_mask)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        \n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for batch in val_dataloader:\n",
    "            inputs, attention_mask, targets = batch\n",
    "            inputs = inputs.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "            targets = targets.to(device)\n",
    "            outputs = model.encode(inputs, attention_mask)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            val_loss += loss.item()\n",
    "    avg_train_loss = train_loss/len(train_dataloader)\n",
    "    avg_val_loss = val_loss/len(val_dataloader)\n",
    "    print(f\"Epoch [{epoch+1}/100] | Train Loss: {avg_train_loss:.4f} | Validation Loss: {avg_val_loss:.4f}\")\n",
    "    train_losses.append(avg_train_loss)\n",
    "    val_losses.append(avg_val_loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "3f6f272a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mask' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[136], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(mask)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mask' is not defined"
     ]
    }
   ],
   "source": [
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1760c5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
