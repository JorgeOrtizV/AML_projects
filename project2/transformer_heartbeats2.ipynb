{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aed1442f",
   "metadata": {},
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cc66686",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler\n",
    "from biosppy.signals import ecg\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92958aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('original_data/train.csv', index_col='id')\n",
    "train_y = data['y']\n",
    "labels = train_y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7f7d6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See if there is any difference between using the filtered heartbeats or not\n",
    "with open('data/heartbeat_templates_ecg.pkl', 'rb') as f:\n",
    "    heartbeats = pickle.load(f)\n",
    "    \n",
    "# with open('data/heartbeat_filtered_ecg.pkl', 'rb') as f:\n",
    "#     heartbeats = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21b483cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(32)\n",
    "\n",
    "def split_indices(n, val_pct):\n",
    "    n_val = int(val_pct*n)\n",
    "    idxs = np.random.permutation(n)\n",
    "    return idxs[n_val:], idxs[:n_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a656b482",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SignalDataset(Dataset):\n",
    "    def __init__(self, signals, lengths, labels):\n",
    "        self.signals = signals\n",
    "        self.labels = labels\n",
    "        self.lengths = lengths\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.signals)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.signals[idx], self.lengths[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a574eabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Be sure that all the heartbeats have the same length\n",
    "\n",
    "# Longest seq of beats\n",
    "# max_length_heartbeats = max([len(i) for i in heartbeats])\n",
    "max_length_heartbeats = 202 # Theres a long seq in test, maybe I can drop it...\n",
    "beat_length = 180 # All heartbeats have the same length\n",
    "\n",
    "# Padded heartbeats\n",
    "padded_heartbeats = []\n",
    "lengths = []\n",
    "\n",
    "# Normalize before padding\n",
    "for i,heartbeat in enumerate(heartbeats):\n",
    "    heartbeats[i] = (heartbeat - heartbeat.mean(axis=-1, keepdims=True)) / heartbeat.std(axis=-1, keepdims=True)\n",
    "    \n",
    "for heartbeat in heartbeats:\n",
    "    length = len(heartbeat)\n",
    "    lengths.append(length)\n",
    "    pad = np.zeros((max_length_heartbeats-length, 180))\n",
    "    padded_heartbeats.append(np.concatenate((heartbeat, pad),axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e527d62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform heartbeats to tensor\n",
    "padded_heartbeats = np.array(padded_heartbeats)\n",
    "padded_heartbeats = torch.tensor(padded_heartbeats, dtype=torch.float32)\n",
    "labels_heartbeats = torch.tensor(labels)\n",
    "lengths_heartbeats = torch.tensor(lengths)\n",
    "\n",
    "# Normalize data per beat\n",
    "# padded_heartbeats = (padded_heartbeats - padded_heartbeats.mean(axis=-1, keepdims=True)) / padded_heartbeats.std(axis=-1, keepdims=True)\n",
    "\n",
    "# Train val split\n",
    "train_idxs, val_idxs = split_indices(len(padded_heartbeats), 0.2)\n",
    "train_x = padded_heartbeats[train_idxs]\n",
    "val_y = labels_heartbeats[val_idxs]\n",
    "train_y = labels_heartbeats[train_idxs]\n",
    "val_x = padded_heartbeats[val_idxs]\n",
    "train_lengths = lengths_heartbeats[train_idxs]\n",
    "val_lengths = lengths_heartbeats[val_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce3bc17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make a dataset for all the individual beats - 1D conv\n",
    "\n",
    "labels_beats = []\n",
    "beats = []\n",
    "\n",
    "for i, beat in enumerate(heartbeats):\n",
    "    samples = beat.shape[0]\n",
    "    beats.append(torch.tensor(beat, dtype=torch.float32))\n",
    "    labels_beats.append(torch.full((samples,), labels[i]))\n",
    "    \n",
    "beats = torch.cat(beats, dim=0)\n",
    "labels_beats = torch.cat(labels_beats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4c07afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train - val split for individual beats\n",
    "\n",
    "train_idxs_beats, val_idxs_beats = split_indices(len(beats), 0.2)\n",
    "train_x_beats = beats[train_idxs_beats]\n",
    "val_y_beats = labels_beats[val_idxs_beats]\n",
    "train_y_beats = labels_beats[train_idxs_beats]\n",
    "val_x_beats = beats[val_idxs_beats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e87c3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the moment training without a scaler but try also with scaler later.\n",
    "# scaler = StandardScaler()\n",
    "# train_x = scaler.fit_transform(train_x)\n",
    "# val_x = scaler.transform(val_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b852220",
   "metadata": {},
   "source": [
    "### Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f156a373",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Signal dataset\n",
    "class SignalDataset(Dataset):\n",
    "    def __init__(self, signals, lengths, labels):\n",
    "        self.signals = signals\n",
    "        self.labels = labels\n",
    "        self.lengths = lengths\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.signals)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.signals[idx], self.lengths[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f24954fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SignalDataset(train_x, train_lengths, train_y)\n",
    "val_dataset = SignalDataset(val_x, val_lengths, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19156d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Theres a big class invariance in our dataset so let's try to fight it with class weights\n",
    "\n",
    "class_counts = torch.tensor([3030, 443, 1474, 170], dtype=torch.float32)\n",
    "class_weights = 1.0/class_counts\n",
    "class_weights = class_weights/class_weights.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "603269e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversample classes with lower appearance\n",
    "sample_weights = [1.0 / class_counts[label] for label in train_y]\n",
    "sample_weights = torch.tensor(sample_weights, dtype=torch.float32)\n",
    "sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67ab42c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128 #64\n",
    "\n",
    "def collate_fn(batch):\n",
    "    signals, lengths, labels = zip(*batch)\n",
    "    signals = torch.stack(signals)\n",
    "    lengths = torch.stack(lengths)\n",
    "    labels = torch.stack(labels)\n",
    "    signals = signals.to(device)\n",
    "    lengths = lengths.to(device)\n",
    "    attention_mask = torch.arange(signals.size(1), device=device).unsqueeze(0) >= lengths.unsqueeze(1)\n",
    "    return signals, attention_mask, labels\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn, sampler=sampler)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6e1e4a",
   "metadata": {},
   "source": [
    "# Transformer for signal beats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0b184c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model:int, seq_len:int, dropout:float):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.seq_len = seq_len\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        pe = torch.zeros(seq_len, d_model) #(seq_len, d_model)\n",
    "        \n",
    "        position = torch.arange(0, seq_len, dtype=torch.float).unsqueeze(1) #(seq_len, 1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float()*(-math.log(10000.0)/d_model))\n",
    "        pe[:,0::2] = torch.sin(position*div_term)\n",
    "        pe[:,1::2] = torch.cos(position*div_term)\n",
    "        \n",
    "        pe = pe.unsqueeze(0) #(1, seq_len, d_model)\n",
    "        \n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + (self.pe[:, :x.shape[1], :]).requires_grad_(False)\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b35b28eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, eps:float = 10**-6):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.eps = eps\n",
    "        self.alpha = nn.Parameter(torch.ones(1))\n",
    "        self.bias = nn.Parameter(torch.zeros(1))\n",
    "        \n",
    "    def forward(self,x):\n",
    "        mean = x.mean(dim=-1, keepdim=True) # We use the last dimension\n",
    "        std = x.std(dim=-1, keepdim=True)\n",
    "        return self.alpha*(x-mean)/(std+self.eps)+self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6132c2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedFwd(nn.Module):\n",
    "    def __init__(self, d_model:int, d_ff:int, dropout:float):\n",
    "        super(FeedFwd, self).__init__()\n",
    "        self.linear1 = nn.Linear(d_model, d_ff)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear2 = nn.Linear(d_ff, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # (b_size, seq_len, d_model) -> (b_size, seq_len, dff) -> (b_size, seq_len, d_model)\n",
    "        x = self.relu(self.linear1(x))\n",
    "        x = self.dropout(self.linear2(x))\n",
    "        return x\n",
    "        #return self.linear2(self.dropout(self.linear1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "079df614",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiheadAttention(nn.Module):\n",
    "    def __init__(self, d_model:int, h:int, dropout:float): # h -> num heads\n",
    "        super(MultiheadAttention, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.h = h\n",
    "        assert d_model % h == 0, \"d_model is not divisible by h\"\n",
    "        \n",
    "        self.d_k = d_model // h # dim of each head\n",
    "        \n",
    "        self.w_q = nn.Linear(d_model, d_model)\n",
    "        self.w_k = nn.Linear(d_model, d_model)\n",
    "        self.w_v = nn.Linear(d_model, d_model)\n",
    "        \n",
    "        self.w_o = nn.Linear(d_model, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    @staticmethod\n",
    "    def attention(query, key, value, mask, dropout):\n",
    "        d_k = query.shape[-1]\n",
    "        attention_scores = (query @ key.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "        if mask != None:\n",
    "            mask = mask.unsqueeze(1).unsqueeze(2) # (b_size, 1, 1, seq_len) -> make this to match the attention_Score size\n",
    "            #attention_scores.masked_fill_(mask == 0, -1e9)\n",
    "            attention_scores.masked_fill_(mask, -1e9)\n",
    "        attention_scores = attention_scores.softmax(dim=-1) # (b_size, h, seq_len, seq_len)\n",
    "        if dropout != None:\n",
    "            attention_scores = dropout(attention_scores)\n",
    "            \n",
    "        return (attention_scores@value), attention_scores\n",
    "        \n",
    "    def forward(self, q, k, v, mask):\n",
    "        query = self.w_q(q) # (b_size, seq_len, d_model) -> (b_size, seq_len, d_model)\n",
    "        key = self.w_k(k)\n",
    "        val = self.w_v(v)\n",
    "        \n",
    "        query = query.view(query.shape[0], query.shape[1], self.h, self.d_k).transpose(1,2) # Divide to heads\n",
    "        key = key.view(key.shape[0], key.shape[1], self.h, self.d_k).transpose(1,2)\n",
    "        val = val.view(val.shape[0], val.shape[1], self.h, self.d_k).transpose(1,2)\n",
    "        # Outpus size at this point (b_size, h, seq_len, d_k)\n",
    "        \n",
    "        # Apply mask\n",
    "        x, self.attention_scores = MultiheadAttention.attention(query, key, val, mask, self.dropout)\n",
    "        \n",
    "        x = x.transpose(1,2).contiguous().view(x.shape[0], -1, self.h*self.d_k) # Go back to (b_size, seq_len, h, d_k) and then (b_size, seq_len, d_model)\n",
    "        \n",
    "        return self.w_o(x) # (b_size, seq_len, d_model)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2acf2090",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualConnection(nn.Module):\n",
    "    def __init__(self, dropout:float):\n",
    "        super(ResidualConnection, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.norm = LayerNorm()\n",
    "        \n",
    "    def forward(self, x, sublayer):\n",
    "        return x + self.dropout(sublayer(self.norm(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d95b4ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, self_attention, feed_forward, dropout):\n",
    "        super(EncoderBlock, self).__init__()\n",
    "        self.self_attention = self_attention\n",
    "        self.feed_forward = feed_forward\n",
    "        self.residual_connections = nn.ModuleList([ResidualConnection(dropout) for _ in range(2)])\n",
    "\n",
    "    \n",
    "    def forward(self, x, src_mask):\n",
    "        x = self.residual_connections[0](x, lambda x: self.self_attention(x, x, x, src_mask))\n",
    "        x = self.residual_connections[1](x, self.feed_forward)\n",
    "        return x\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "61533910",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.layers = layers\n",
    "        self.norm = LayerNorm()\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b382ec98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, encoder, pos_enc, src_size, d_model, output_dim, hidden=128):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.pos_enc = pos_enc\n",
    "        self.input_proj = nn.Linear(src_size, d_model)\n",
    "        self.hidden = nn.Linear(d_model, hidden)\n",
    "        self.out_proj = nn.Linear(hidden, output_dim)\n",
    "        self.act = nn.ReLU()\n",
    "        \n",
    "    def encode(self, src, src_mask):\n",
    "        src = self.input_proj(src)\n",
    "        src = self.pos_enc(src)\n",
    "        encoder_output = self.encoder(src, src_mask)\n",
    "        # MLP\n",
    "        pre_out = encoder_output.mean(dim=1) #Avg pooling over seq length -> really helpful?\n",
    "        # Attention pooling?\n",
    "#         attention_weights = nn.Softmax(dim=1)(self.attention(encoder_output))\n",
    "#         pre_out = torch.sum(encoder_output * attention_weights.unsqueeze(-1), dim=1)\n",
    "        hidden_out = self.act(self.hidden(pre_out))\n",
    "        logits = self.out_proj(hidden_out)\n",
    "        return logits\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ff3e1c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_transformer(src_size, src_seq_len, d_model=512, N=6, h=8, dropout=0.1, d_ff=2048, output_dim=4):\n",
    "    # Positional encoding\n",
    "    pe = PositionalEncoding(d_model, src_seq_len, dropout)\n",
    "    # Encoder\n",
    "    encoder_blocks = []\n",
    "    for _ in range(N):\n",
    "        encoder_self_attention = MultiheadAttention(d_model, h, dropout)\n",
    "        feed_fwd = FeedFwd(d_model, d_ff, dropout)\n",
    "        encoder_block = EncoderBlock(encoder_self_attention, feed_fwd, dropout)\n",
    "        encoder_blocks.append(encoder_block)\n",
    "        \n",
    "    encoder = Encoder(nn.ModuleList(encoder_blocks))\n",
    "    \n",
    "    transformer = Transformer(encoder, pe, src_size, d_model, output_dim)\n",
    "    \n",
    "    for p in transformer.parameters():\n",
    "        if p.dim()>1:\n",
    "            nn.init.xavier_uniform_(p)\n",
    "            \n",
    "    return transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "92c09a0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▌                                                                              | 1/50 [06:31<5:20:01, 391.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50] | Train Loss: 0.6613 | Validation Loss: 1.4002 | Train acc: 0.4309 | Val acc: 0.1114 | f1 score: 0.1114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|███▏                                                                            | 2/50 [13:02<5:12:58, 391.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50] | Train Loss: 0.3881 | Validation Loss: 1.2071 | Train acc: 0.5012 | Val acc: 0.2835 | f1 score: 0.2835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|████▊                                                                           | 3/50 [19:35<5:06:57, 391.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/50] | Train Loss: 0.3280 | Validation Loss: 1.2610 | Train acc: 0.5752 | Val acc: 0.3705 | f1 score: 0.3705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|██████▍                                                                         | 4/50 [26:06<5:00:15, 391.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/50] | Train Loss: 0.2812 | Validation Loss: 1.2943 | Train acc: 0.6385 | Val acc: 0.3255 | f1 score: 0.3255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████████                                                                        | 5/50 [32:39<4:54:03, 392.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50] | Train Loss: 0.2519 | Validation Loss: 1.1194 | Train acc: 0.6380 | Val acc: 0.4506 | f1 score: 0.4506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█████████▌                                                                      | 6/50 [39:10<4:47:20, 391.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/50] | Train Loss: 0.2128 | Validation Loss: 1.5542 | Train acc: 0.6876 | Val acc: 0.3333 | f1 score: 0.3333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|███████████▏                                                                    | 7/50 [45:44<4:41:14, 392.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/50] | Train Loss: 0.1920 | Validation Loss: 1.1403 | Train acc: 0.7035 | Val acc: 0.4819 | f1 score: 0.4819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|████████████▊                                                                   | 8/50 [52:16<4:34:40, 392.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/50] | Train Loss: 0.1969 | Validation Loss: 1.1711 | Train acc: 0.6993 | Val acc: 0.4301 | f1 score: 0.4301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|██████████████▍                                                                 | 9/50 [58:50<4:28:23, 392.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/50] | Train Loss: 0.1625 | Validation Loss: 1.2096 | Train acc: 0.7408 | Val acc: 0.4985 | f1 score: 0.4985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|███████████████▍                                                             | 10/50 [1:05:22<4:21:40, 392.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50] | Train Loss: 0.1768 | Validation Loss: 1.2400 | Train acc: 0.7399 | Val acc: 0.4809 | f1 score: 0.4809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|████████████████▉                                                            | 11/50 [1:11:56<4:15:28, 393.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/50] | Train Loss: 0.1436 | Validation Loss: 1.2340 | Train acc: 0.7714 | Val acc: 0.5415 | f1 score: 0.5415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██████████████████▍                                                          | 12/50 [1:18:29<4:08:49, 392.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/50] | Train Loss: 0.1437 | Validation Loss: 1.2725 | Train acc: 0.7638 | Val acc: 0.5572 | f1 score: 0.5572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|████████████████████                                                         | 13/50 [1:25:03<4:02:32, 393.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/50] | Train Loss: 0.1250 | Validation Loss: 1.2634 | Train acc: 0.7824 | Val acc: 0.5249 | f1 score: 0.5249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|█████████████████████▌                                                       | 14/50 [1:31:35<3:55:50, 393.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/50] | Train Loss: 0.1176 | Validation Loss: 1.3113 | Train acc: 0.8031 | Val acc: 0.5543 | f1 score: 0.5543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███████████████████████                                                      | 15/50 [1:38:09<3:49:26, 393.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/50] | Train Loss: 0.1246 | Validation Loss: 1.2286 | Train acc: 0.7929 | Val acc: 0.5425 | f1 score: 0.5425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|████████████████████████▋                                                    | 16/50 [1:44:42<3:42:42, 393.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/50] | Train Loss: 0.1102 | Validation Loss: 1.3559 | Train acc: 0.8100 | Val acc: 0.5582 | f1 score: 0.5582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|██████████████████████████▏                                                  | 17/50 [1:51:16<3:36:20, 393.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/50] | Train Loss: 0.1130 | Validation Loss: 1.3330 | Train acc: 0.8109 | Val acc: 0.5533 | f1 score: 0.5533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███████████████████████████▋                                                 | 18/50 [1:57:48<3:29:32, 392.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/50] | Train Loss: 0.1114 | Validation Loss: 1.3287 | Train acc: 0.8048 | Val acc: 0.5611 | f1 score: 0.5611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|█████████████████████████████▎                                               | 19/50 [2:04:21<3:23:05, 393.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/50] | Train Loss: 0.0948 | Validation Loss: 1.3656 | Train acc: 0.8324 | Val acc: 0.5787 | f1 score: 0.5787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|██████████████████████████████▊                                              | 20/50 [2:10:53<3:16:20, 392.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/50] | Train Loss: 0.0955 | Validation Loss: 1.3593 | Train acc: 0.8344 | Val acc: 0.5543 | f1 score: 0.5543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████████████████████████████████▎                                            | 21/50 [2:17:26<3:09:56, 392.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/50] | Train Loss: 0.0887 | Validation Loss: 1.3029 | Train acc: 0.8415 | Val acc: 0.5718 | f1 score: 0.5718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|█████████████████████████████████▉                                           | 22/50 [2:23:59<3:03:17, 392.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/50] | Train Loss: 0.0960 | Validation Loss: 1.3866 | Train acc: 0.8341 | Val acc: 0.5630 | f1 score: 0.5630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|███████████████████████████████████▍                                         | 23/50 [2:30:32<2:56:51, 393.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/50] | Train Loss: 0.0971 | Validation Loss: 1.3866 | Train acc: 0.8271 | Val acc: 0.5630 | f1 score: 0.5630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████████████████████████████████████▉                                        | 24/50 [2:37:05<2:50:13, 392.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/50] | Train Loss: 0.0892 | Validation Loss: 1.4070 | Train acc: 0.8363 | Val acc: 0.5650 | f1 score: 0.5650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|██████████████████████████████████████▌                                      | 25/50 [2:43:39<2:43:49, 393.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/50] | Train Loss: 0.0842 | Validation Loss: 1.3780 | Train acc: 0.8461 | Val acc: 0.5728 | f1 score: 0.5728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|████████████████████████████████████████                                     | 26/50 [2:50:11<2:37:08, 392.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/50] | Train Loss: 0.0840 | Validation Loss: 1.4164 | Train acc: 0.8473 | Val acc: 0.5797 | f1 score: 0.5797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████████████████████████████████████████▌                                   | 27/50 [2:56:45<2:30:42, 393.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/50] | Train Loss: 0.0818 | Validation Loss: 1.4022 | Train acc: 0.8451 | Val acc: 0.5797 | f1 score: 0.5797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|███████████████████████████████████████████                                  | 28/50 [3:03:17<2:24:02, 392.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/50] | Train Loss: 0.0822 | Validation Loss: 1.4006 | Train acc: 0.8569 | Val acc: 0.5640 | f1 score: 0.5640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|████████████████████████████████████████████▋                                | 29/50 [3:09:50<2:17:35, 393.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/50] | Train Loss: 0.0768 | Validation Loss: 1.3688 | Train acc: 0.8517 | Val acc: 0.5758 | f1 score: 0.5758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████████████████████████████████████████████▏                              | 30/50 [3:16:23<2:10:56, 392.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/50] | Train Loss: 0.0785 | Validation Loss: 1.4211 | Train acc: 0.8527 | Val acc: 0.5934 | f1 score: 0.5934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|███████████████████████████████████████████████▋                             | 31/50 [3:22:56<2:04:28, 393.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/50] | Train Loss: 0.0716 | Validation Loss: 1.4282 | Train acc: 0.8608 | Val acc: 0.5885 | f1 score: 0.5885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|█████████████████████████████████████████████████▎                           | 32/50 [3:29:28<1:57:48, 392.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/50] | Train Loss: 0.0747 | Validation Loss: 1.4834 | Train acc: 0.8456 | Val acc: 0.5660 | f1 score: 0.5660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████████████████████████████████████████████████▊                          | 33/50 [3:36:02<1:51:22, 393.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/50] | Train Loss: 0.0756 | Validation Loss: 1.4446 | Train acc: 0.8608 | Val acc: 0.5738 | f1 score: 0.5738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|████████████████████████████████████████████████████▎                        | 34/50 [3:42:34<1:44:43, 392.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/50] | Train Loss: 0.0680 | Validation Loss: 1.4500 | Train acc: 0.8615 | Val acc: 0.5914 | f1 score: 0.5914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|█████████████████████████████████████████████████████▉                       | 35/50 [3:49:08<1:38:15, 393.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/50] | Train Loss: 0.0760 | Validation Loss: 1.4852 | Train acc: 0.8615 | Val acc: 0.5826 | f1 score: 0.5826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████████████████████████████████████████████████████▍                     | 36/50 [3:55:43<1:31:51, 393.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/50] | Train Loss: 0.0763 | Validation Loss: 1.4427 | Train acc: 0.8583 | Val acc: 0.5846 | f1 score: 0.5846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|████████████████████████████████████████████████████████▉                    | 37/50 [4:02:16<1:25:16, 393.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/50] | Train Loss: 0.0656 | Validation Loss: 1.4342 | Train acc: 0.8725 | Val acc: 0.5855 | f1 score: 0.5855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|██████████████████████████████████████████████████████████▌                  | 38/50 [4:08:48<1:18:37, 393.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/50] | Train Loss: 0.0706 | Validation Loss: 1.4262 | Train acc: 0.8598 | Val acc: 0.5836 | f1 score: 0.5836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|████████████████████████████████████████████████████████████                 | 39/50 [4:15:22<1:12:06, 393.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/50] | Train Loss: 0.0729 | Validation Loss: 1.4597 | Train acc: 0.8642 | Val acc: 0.5846 | f1 score: 0.5846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|█████████████████████████████████████████████████████████████▌               | 40/50 [4:21:54<1:05:30, 393.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/50] | Train Loss: 0.0700 | Validation Loss: 1.4613 | Train acc: 0.8681 | Val acc: 0.5826 | f1 score: 0.5826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████████████████████████████████████████████████████████████▊              | 41/50 [4:28:28<58:58, 393.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/50] | Train Loss: 0.0732 | Validation Loss: 1.4428 | Train acc: 0.8613 | Val acc: 0.5836 | f1 score: 0.5836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|██████████████████████████████████████████████████████████████████▎            | 42/50 [4:35:00<52:22, 392.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/50] | Train Loss: 0.0678 | Validation Loss: 1.4523 | Train acc: 0.8696 | Val acc: 0.5836 | f1 score: 0.5836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|███████████████████████████████████████████████████████████████████▉           | 43/50 [4:41:34<45:52, 393.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/50] | Train Loss: 0.0727 | Validation Loss: 1.4724 | Train acc: 0.8654 | Val acc: 0.5894 | f1 score: 0.5894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|█████████████████████████████████████████████████████████████████████▌         | 44/50 [4:48:06<39:17, 392.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/50] | Train Loss: 0.0704 | Validation Loss: 1.4476 | Train acc: 0.8635 | Val acc: 0.5885 | f1 score: 0.5885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|███████████████████████████████████████████████████████████████████████        | 45/50 [4:54:40<32:46, 393.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/50] | Train Loss: 0.0735 | Validation Loss: 1.4471 | Train acc: 0.8661 | Val acc: 0.5904 | f1 score: 0.5904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|████████████████████████████████████████████████████████████████████████▋      | 46/50 [5:01:13<26:11, 392.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/50] | Train Loss: 0.0689 | Validation Loss: 1.4660 | Train acc: 0.8752 | Val acc: 0.5816 | f1 score: 0.5816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|██████████████████████████████████████████████████████████████████████████▎    | 47/50 [5:07:47<19:39, 393.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/50] | Train Loss: 0.0726 | Validation Loss: 1.4592 | Train acc: 0.8657 | Val acc: 0.5904 | f1 score: 0.5904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|███████████████████████████████████████████████████████████████████████████▊   | 48/50 [5:14:19<13:05, 392.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/50] | Train Loss: 0.0688 | Validation Loss: 1.4591 | Train acc: 0.8698 | Val acc: 0.5904 | f1 score: 0.5904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████████████████████████████████████████████████████████████████████████▍ | 49/50 [5:20:54<06:33, 393.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/50] | Train Loss: 0.0713 | Validation Loss: 1.4458 | Train acc: 0.8649 | Val acc: 0.5846 | f1 score: 0.5846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 50/50 [5:27:26<00:00, 392.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/50] | Train Loss: 0.0699 | Validation Loss: 1.4604 | Train acc: 0.8630 | Val acc: 0.5846 | f1 score: 0.5846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "d_model = 512\n",
    "nhead = 8\n",
    "num_encoder_layers=4\n",
    "num_decoder_layers = 0\n",
    "dim_feedforward = 2048\n",
    "dropout = 0.1\n",
    "output_dim = 4\n",
    "LR = 1e-4\n",
    "EPOCHS = 50\n",
    "\n",
    "# src_seq_len=max_length_heartbeats\n",
    "model = build_transformer(src_size=180, src_seq_len=max_length_heartbeats, d_model=d_model, N=num_encoder_layers, h=nhead, dropout=dropout, d_ff=dim_feedforward, output_dim=4)\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=1e-4)\n",
    "loss_fn = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    model.train()\n",
    "    train_loss=0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    for batch in train_dataloader:\n",
    "        inputs, attention_mask, targets = batch\n",
    "        inputs = inputs.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        targets = targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        # Debug\n",
    "#         inputs = torch.ones((1, 2, 180), device=device)\n",
    "#         mask = torch.tensor([[False, True]], device=device)\n",
    "        outputs = model.encode(inputs, attention_mask)\n",
    "        pred = torch.argmax(outputs, dim=1)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        \n",
    "        all_labels.extend(targets.detach().cpu().tolist())\n",
    "        all_preds.extend(pred.detach().cpu().tolist())\n",
    "        \n",
    "    val_loss = 0\n",
    "    all_preds_val = []\n",
    "    all_labels_val = []\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for batch in val_dataloader:\n",
    "            inputs, attention_mask, targets = batch\n",
    "            inputs = inputs.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "            targets = targets.to(device)\n",
    "            outputs = model.encode(inputs, attention_mask)\n",
    "            pred = torch.argmax(outputs, dim=1)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            all_labels_val.extend(targets.detach().cpu().tolist())\n",
    "            all_preds_val.extend(pred.detach().cpu().tolist())\n",
    "            \n",
    "    avg_train_loss = train_loss/len(train_dataloader)\n",
    "    avg_val_loss = val_loss/len(val_dataloader)\n",
    "    scheduler.step(avg_val_loss)\n",
    "    train_acc = accuracy_score(all_labels, all_preds)\n",
    "    val_acc = accuracy_score(all_labels_val, all_preds_val)\n",
    "    f1 = f1_score(all_labels_val, all_preds_val, average='micro')\n",
    "    print(f\"Epoch [{epoch+1}/{EPOCHS}] | Train Loss: {avg_train_loss:.4f} | Validation Loss: {avg_val_loss:.4f} | Train acc: {train_acc:.4f} | Val acc: {val_acc:.4f} | f1 score: {f1:.4f}\")\n",
    "    train_losses.append(avg_train_loss)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    \n",
    "    # Check for vanishing gradient:\n",
    "#     with torch.no_grad():\n",
    "#         for name, param in model.named_parameters():\n",
    "#             if param.grad is not None:\n",
    "#                 print(f\"{name} grad norm: {param.grad.norm()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cdcd9eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 7.3150, -4.5752,  6.8134, -1.4315],\n",
      "        [-0.5778,  5.2611, -0.1853, -5.5692],\n",
      "        [ 6.0844, -0.5860,  3.4989, -3.1107],\n",
      "        [ 6.9042, -3.0260,  5.4810, -2.4056],\n",
      "        [ 5.4913, -0.8366,  5.3401, -3.1009],\n",
      "        [ 7.0985, -3.3910,  4.9623, -3.0410],\n",
      "        [ 7.3649, -2.9151,  4.9623, -0.9886],\n",
      "        [ 7.4181, -2.1530,  5.8066, -2.9149],\n",
      "        [ 5.0642, -1.6110,  5.6315, -4.2222],\n",
      "        [ 1.9198,  3.3984,  4.4088, -5.2286],\n",
      "        [ 4.4639, -3.8782,  7.6935, -3.2776],\n",
      "        [ 5.1656, -2.1504,  6.8736,  0.2348],\n",
      "        [ 2.4401, -0.5813,  1.3699,  6.3070],\n",
      "        [ 4.3097, -2.7205,  7.7122, -4.0853],\n",
      "        [ 0.9133,  1.4447,  5.4773, -0.0272],\n",
      "        [ 6.7607, -1.6373,  4.3717, -3.9347],\n",
      "        [ 2.7647,  0.9517,  4.3947, -3.4192],\n",
      "        [ 7.3140, -3.5348,  6.2206, -2.6685],\n",
      "        [ 7.2787, -3.4936,  4.2624, -2.4108],\n",
      "        [ 3.7639,  2.0533,  4.6435, -4.7214],\n",
      "        [ 3.2696,  1.9262,  3.7876, -3.9049],\n",
      "        [ 6.5490, -2.6399,  5.1341, -2.1502],\n",
      "        [ 5.1941,  0.6351,  7.0161, -4.1950],\n",
      "        [ 7.2275, -6.3015,  1.9569, -2.5356],\n",
      "        [ 3.6546,  0.1210,  3.7435, -2.4468],\n",
      "        [ 3.1864, -1.1761,  4.5994, -2.8163],\n",
      "        [ 8.0654, -3.3786,  4.4167, -2.1376],\n",
      "        [ 4.9973, -1.2868,  5.5977, -0.7481],\n",
      "        [-0.5330,  6.2656,  2.0315, -5.2239],\n",
      "        [ 5.2567, -0.1188,  5.6042, -4.3612],\n",
      "        [ 6.8842, -2.2595,  6.4771, -3.3354],\n",
      "        [ 8.2124, -3.5086,  4.4384, -2.6854],\n",
      "        [ 6.4353, -2.9245,  2.7144, -1.8204],\n",
      "        [ 5.9213, -5.3310,  7.4485, -1.4742],\n",
      "        [ 6.0278, -2.4865,  4.9118, -0.6907],\n",
      "        [ 6.5067, -4.4586,  6.3686, -1.2539],\n",
      "        [-1.0206,  3.4993, -1.2391, -0.9896],\n",
      "        [ 4.5702, -0.3011,  5.1314, -3.4319],\n",
      "        [ 1.7387,  3.3276,  3.1931, -2.2035],\n",
      "        [ 6.0680, -2.3406,  7.2880, -1.3691],\n",
      "        [-0.5739,  5.8973,  2.1628, -6.2097],\n",
      "        [ 2.7591,  2.8247,  2.6013, -6.2301],\n",
      "        [ 6.1768, -2.6739,  5.4462, -2.6771],\n",
      "        [ 6.3501, -3.0693,  6.0210, -2.7640],\n",
      "        [ 4.4364, -1.0890,  2.3895,  6.7991],\n",
      "        [-2.5652, -0.9018,  7.9649, -1.5513],\n",
      "        [ 6.4205, -2.7529,  6.2910, -2.1688],\n",
      "        [ 7.6699, -3.9990,  5.7514, -1.5374],\n",
      "        [ 2.0009,  5.6040,  2.5122, -6.3335],\n",
      "        [ 3.5685,  2.1759,  4.2944, -5.2756],\n",
      "        [ 4.6952,  0.1059,  5.0484, -2.4088],\n",
      "        [ 0.4021,  2.1468,  0.8162, -6.4051],\n",
      "        [ 6.1307, -3.7715,  5.5149, -2.1904],\n",
      "        [ 2.6914, -3.8538,  2.9038, -7.7907],\n",
      "        [-1.0689,  6.5716,  1.0977, -6.6534],\n",
      "        [ 0.4853,  3.6630,  4.6762, -0.0220],\n",
      "        [ 2.8128, -0.0925,  6.3701, -3.1963],\n",
      "        [-1.0393,  6.1034,  2.5160, -5.3461],\n",
      "        [ 4.8230, -4.5901,  3.8386,  7.2458],\n",
      "        [ 6.2136, -4.9470,  4.0117,  0.6443],\n",
      "        [ 5.0420, -4.3117,  6.5477,  2.8379],\n",
      "        [ 4.0886, -6.0775,  4.2427, -6.9685],\n",
      "        [ 1.3781,  0.0779,  4.1041, -2.5144],\n",
      "        [ 5.6769, -3.3251,  7.5186, -1.9341],\n",
      "        [ 6.1942, -3.4180,  5.4869, -0.2382],\n",
      "        [ 0.8848,  0.7530,  4.6604, -2.7709],\n",
      "        [-1.9225,  6.6672,  3.1035, -5.5234],\n",
      "        [-2.6969,  6.0226,  2.0403, -2.8716],\n",
      "        [ 1.9951,  4.4424,  0.7265, -3.2388],\n",
      "        [ 3.7929,  0.4988,  5.3543, -5.0790],\n",
      "        [ 5.7160, -7.1238,  4.0089, -0.3523],\n",
      "        [ 1.0573,  1.4179,  6.7768, -3.9151],\n",
      "        [ 5.2191, -3.4878,  3.4751,  5.0509],\n",
      "        [ 7.8407, -4.9954,  5.6322, -1.8684],\n",
      "        [ 2.0750,  0.5208,  0.1196, -7.8585],\n",
      "        [ 1.1601,  2.7294,  2.7479, -6.1349],\n",
      "        [ 7.0150, -3.7225,  5.7140, -2.8669],\n",
      "        [ 0.6707,  3.3867,  1.3388, -3.6636],\n",
      "        [ 1.1862,  4.9492,  2.5234, -3.2443],\n",
      "        [ 1.5802, -3.0533,  2.8671, 10.6023],\n",
      "        [ 0.2998, -0.6720,  4.5802,  3.9147],\n",
      "        [ 5.8658, -2.9923,  5.9915, -2.7923],\n",
      "        [ 1.6656,  3.1633,  0.8790,  5.6444],\n",
      "        [ 1.9124,  1.0958,  3.8439, -5.4173],\n",
      "        [ 2.8620,  1.7509,  4.3931, -4.9263],\n",
      "        [ 1.7439,  2.9635,  4.0482, -5.7143],\n",
      "        [ 6.9973, -1.8466,  4.3311, -4.1767],\n",
      "        [ 5.7157,  0.4584,  3.5081, -3.8256],\n",
      "        [ 4.2256, -0.1412,  5.6788, -4.4916],\n",
      "        [-1.5719,  5.1325, -0.4723, -6.3880],\n",
      "        [ 5.6391, -1.4435,  4.7188, -4.2900],\n",
      "        [ 4.9720, -3.5539,  6.0876, -4.3067],\n",
      "        [ 4.1811, -8.2153,  4.8618,  5.2164],\n",
      "        [ 7.7892, -4.4207,  5.5963, -2.5206],\n",
      "        [ 5.9785, -2.1057,  6.2833, -2.1488],\n",
      "        [ 5.0099, -2.6860,  6.3090, -4.6299],\n",
      "        [ 5.6970, -1.9747,  4.3138, -4.5180],\n",
      "        [ 0.1694,  5.5153,  2.0193, -6.1485],\n",
      "        [ 5.6148, -2.3585,  6.1701, -3.0118],\n",
      "        [ 3.2361, -0.7999,  5.1264,  1.7675],\n",
      "        [ 5.1333, -6.2441,  3.8757, -7.9051],\n",
      "        [ 0.5985,  7.2055,  0.8173, -5.0063],\n",
      "        [ 4.8688, -4.3151,  6.7312, -0.6532],\n",
      "        [ 6.3473, -1.5766,  6.2751, -3.8160],\n",
      "        [ 1.1806,  3.8306,  4.4129, -4.9941],\n",
      "        [ 5.2671, -1.5958,  5.5336, -3.5959],\n",
      "        [ 3.2304, -5.5668,  0.7870, 14.0388],\n",
      "        [ 2.7705, -2.5061,  2.0508,  9.1682],\n",
      "        [ 6.2126, -2.7031,  5.4808, -3.4277],\n",
      "        [-2.3842,  9.5433,  0.2946, -4.9223],\n",
      "        [ 5.4808, -5.0936,  2.8384, -3.6429],\n",
      "        [ 4.9434, -5.4994,  4.0405, -8.2775],\n",
      "        [ 7.2144, -3.3212,  5.3861, -2.4816],\n",
      "        [ 6.5604, -2.3363,  5.8411, -2.2925],\n",
      "        [ 0.7235,  5.6334,  4.7075, -3.3350],\n",
      "        [ 5.1275, -0.2868,  4.6037, -3.5179],\n",
      "        [ 6.5089, -4.3406,  6.9882, -2.6792],\n",
      "        [-0.9219,  5.2357,  0.2604, -6.2101],\n",
      "        [ 5.7557, -0.8987,  6.7359, -4.2119],\n",
      "        [ 0.0580, -1.4255,  2.9529,  5.3364],\n",
      "        [ 1.7099,  3.2198,  4.2931, -6.6190],\n",
      "        [ 6.4544, -0.1965,  5.3387, -1.5639],\n",
      "        [ 2.9721, -0.3255,  0.6719, -8.6778],\n",
      "        [ 7.5469, -3.0988,  6.0254, -2.7925],\n",
      "        [ 4.5089, -0.0918,  4.6989, -3.7169],\n",
      "        [ 5.8295,  0.6682,  4.5678, -2.8962],\n",
      "        [ 6.2675, -7.8898,  2.8904,  0.3600]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e219570",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bdf467",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(labels, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc8e0f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 3030, 1: 443, 2: 1474, 3: 170}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07a8a12",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "14dadebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = pd.read_csv('original_data/test.csv', index_col='id')\n",
    "\n",
    "filtered_signal_test = []\n",
    "beats_test = []\n",
    "for i in range(len(test_x)):\n",
    "    output = ecg.ecg(test_x.loc[i].dropna().to_numpy(dtype='float32'), sampling_rate=300, show=False)\n",
    "    filtered = output['filtered']\n",
    "    beat = output['templates']\n",
    "    filtered_signal_test.append(filtered)\n",
    "    beats_test.append(beat)\n",
    "    if len(filtered) < 1:\n",
    "        print('filtered {} length is less than one'.format(i))\n",
    "    if len(beat) < 1:\n",
    "        print('Beat {} length is less than one'.format(i))\n",
    "        \n",
    "with open('data/filtered_ecg_test.pkl', 'wb') as f:\n",
    "    pickle.dump(filtered_signal_test, f)\n",
    "    \n",
    "with open('data/heartbeat_templates_ecg_test.pkl', 'wb') as f:\n",
    "    pickle.dump(beats_test, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0760f810",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/heartbeat_templates_ecg_test.pkl', 'rb') as f:\n",
    "    heartbeats = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6ac4c7db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3411"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(heartbeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7e256f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length_heartbeats = 159\n",
    "beat_length = 180 # All heartbeats have the same length\n",
    "\n",
    "# Padded heartbeats\n",
    "padded_heartbeats = []\n",
    "lengths = []\n",
    "\n",
    "# Should I change the normalizing strategy here??? It is not learned from train data\n",
    "for i,heartbeat in enumerate(heartbeats):\n",
    "#     if heartbeat.shape[0] > 159:\n",
    "#         heartbeat = heartbeat[:159, :]\n",
    "    heartbeats[i] = (heartbeat - heartbeat.mean(axis=-1, keepdims=True)) / heartbeat.std(axis=-1, keepdims=True)\n",
    "\n",
    "count = 0\n",
    "for heartbeat in heartbeats:\n",
    "    length = len(heartbeat)\n",
    "    lengths.append(length)\n",
    "    pad = np.zeros((max_length_heartbeats-length, 180))\n",
    "    padded_heartbeats.append(np.concatenate((heartbeat, pad),axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7596f99f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3411"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(padded_heartbeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e0954f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_heartbeats = np.array(padded_heartbeats)\n",
    "padded_heartbeats = torch.tensor(padded_heartbeats, dtype=torch.float32)\n",
    "labels_heartbeats = torch.tensor(labels)\n",
    "lengths_heartbeats = torch.tensor(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0edfa1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = SignalDataset(padded_heartbeats, lengths_heartbeats, lengths_heartbeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "46935791",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6d40f34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [0 2 0 ... 2 0 1]\n",
      "3411\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "all_preds = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        inputs, attention_mask, targets = batch\n",
    "        inputs = inputs.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        targets = targets.to(device)\n",
    "        outputs = model.encode(inputs, attention_mask)\n",
    "        pred = torch.argmax(outputs, dim=1)\n",
    "        all_preds.extend(pred.detach().cpu().tolist())\n",
    "        \n",
    "# Convert predictions to a numpy array\n",
    "predictions = np.array(all_preds)\n",
    "\n",
    "print(\"Predictions:\", predictions)\n",
    "# length should be 3411\n",
    "print(len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e630606c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate IDs for each signal in the test set\n",
    "ids = np.arange(len(predictions))\n",
    "\n",
    "# Create a DataFrame for submission\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': ids,\n",
    "    'y': predictions\n",
    "})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "submission_df.to_csv('./data/predictions/test_preds2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0a4afb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
